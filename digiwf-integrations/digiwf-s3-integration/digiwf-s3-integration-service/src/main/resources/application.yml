spring:
  application.name: @project.artifactId@
  banner.location: banner.txt

  flyway:
    enabled: true
    #locations: "classpath:db/migration/{vendor}"

  # Spring data rest
  data:
    rest:
      # Definition of page size for PagingAndSortingRepository
      max-page-size: 0x7fffffff
      default-page-size: 0x7fffffff
      return-body-on-update: true
      return-body-on-create: true

  # Spring JPA
  datasource:
    url: '${S3INTEGRATION_DATASOURCE_URL}'
    username: '${S3INTEGRATION_DATASOURCE_USER}'
    password: '${S3INTEGRATION_DATASOURCE_PASSWORD}'
    driver-class-name: '${S3INTEGRATION_DATASOURCE_DRIVERCLASSNAME}'
  jpa:
    database-platform: '${S3INTEGRATION_DATABASE_PLATFORM}'
    hibernate:
      naming:
        physical-strategy: org.hibernate.boot.model.naming.PhysicalNamingStrategyStandardImpl
      ddl-auto: update

  cloud:
    stream:
      kafka:
        binder:
          producerProperties:
            value:
              serializer: org.springframework.kafka.support.serializer.JsonSerializer
            key:
              serializer: org.springframework.kafka.support.serializer.JsonSerializer
          consumerProperties:
            auto:
              offset:
                reset: latest
            key:
              deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
            value:
              deserializer: org.springframework.kafka.support.serializer.JsonDeserializer
          configuration:
            security:
              protocol: ${KAFKA_SECURITY_PROTOCOL:PLAINTEXT}
          brokers: ${KAFKA_BOOTSTRAP_SERVER:localhost}:${KAFKA_BOOTSTRAP_SERVER_PORT:29092}
      bindings:
        functionRouter-in-0:
          group: ${digiwf.streaming.group}
          destination: ${digiwf.streaming.s3.topics}
        sendCorrelateMessage-out-0:
          destination: ${digiwf.streaming.engine.topics}
        sendMessage-out-0:
          destination: ${digiwf.streaming.engine.topics}
      default:
        consumer:
          maxAttempts: '1'
      default-binder: kafka
      function:
        routing:
          enabled: 'true'
    function:
      definition: functionRouter;sendMessage;sendCorrelateMessage;
  kafka:
    consumer:
      properties:
        spring:
          json:
            trusted:
              packages: '*'

# Define the local keycloak realm here
# realm: "${SSO_REALM}"

security:
  oauth2:
    resource:
      jwk:
        key-set-uri: ${SSO_BASE_URL}/realms/${SSO_REALM}/protocol/openid-connect/certs
      user-info-uri: ${SSO_BASE_URL}/realms/${SSO_REALM}/protocol/openid-connect/userinfo
      prefer-token-info: false
    client:
      client-id: ${SSO_ENGINE_CLIENT_ID}

digiwf:
  streaming:
    s3:
      topics: dwf-s3-${DIGIWF_ENV}
    engine:
      topics: dwf-digiwf-engine-${DIGIWF_ENV}
    group: dwf-s3-service

server:
  port: "${S3_INTEGRATION_SERVER_PORT:8080}"
  error:
    include-exception: false
    include-stacktrace: never
    whitelabel:
      enabled: false

# Config for spring actuator endpoints
management:
  server.port: "${S3_INTEGRATION_SERVER_PORT:8080}"
  endpoints:
    enabled-by-default: false
    web:
      exposure:
        include: health, info, prometheus
      path-mapping:
        prometheus: metrics
  endpoint:
    health.enabled: true
    info.enabled: true
    prometheus.enabled: true
info:
  application:
    name: @project.artifactId@
    version: @project.version@

io:
  muenchendigital:
    digiwf:
      s3:
        bucketname: ${S3_BUCKETNAME}
        accesskey: ${S3_ACCESSKEY}
        url: ${S3_URL:http://localhost:9000}
        secretkey: ${S3_SECRETKEY}
        client:
          document-storage-url: "${DOCUMENT_STORAGE_HOST:http://localhost}:${DOCUMENT_STORAGE_PORT:8080}"
          securityEnabled: false
        proxyUrl: "${S3_PROXY_HOST}:${S3_PROXY_PORT}"
        cronjob:
          cleanup:
            unused-files: 0 15 10 16 * ?
            expired-files: 0 15 10 15 * ?
        proxyEnabled: 'false'
      streaming:
        typeMappings:
          createPresignedUrl: createPresignedUrl
