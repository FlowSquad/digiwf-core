# Use this only in dev environments. It's not intended for production usage.
version: '3.9'
services:
  digiwf-engine:
    image: itatm/digiwf-engine-service-community:dev
    container_name: digiwf-engine
    depends_on:
      keycloak-init:
        condition: service_completed_successfully
    env_file:
      - local-docker.env
    ports:
      - "39146:39146"
    environment:
      SPRING_PROFILES_ACTIVE: "local, streaming, no-mail, no-ldap"
      ENGINE_DATASOURCE_URL: "jdbc:postgresql://host.docker.internal:25433/enginedb"
      KAFKA_BOOTSTRAP_SERVER: "kafka"
      KAFKA_BOOTSTRAP_SERVER_PORT: "9092"
      DOCUMENT_STORAGE_HOST: "http://host.docker.internal"
      S3_URL: "http://host.docker.internal:9000"
    extra_hosts:
      - "host.docker.internal:host-gateway"
    profiles:
      - all # enable with --profile all
    networks:
      - internal

  digiwf-tasklist:
    image: itatm/digiwf-tasklist:dev
    container_name: digiwf-tasklist
    ports:
      - "8091:8080"
    profiles:
      - all # enable with --profile all
    networks:
      - internal

  digiwf-gateway:
    image: itatm/digiwf-gateway:dev
    container_name: digiwf-gateway
    depends_on:
      keycloak-init:
        condition: service_completed_successfully
    env_file:
      - local-docker.env
    ports:
      - "8082:8082"
    environment:
      SPRING_PROFILES_ACTIVE: "local,docker"
    profiles:
      - all # enable with --profile all
    extra_hosts:
      - "host.docker.internal:host-gateway"
    networks:
      - internal

  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    container_name: zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    ports:
      - '22181:2181'
    networks:
      - internal

  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - '29092:29092'
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    networks:
      - internal

  kafka-init:
    image: confluentinc/cp-kafka:latest
    container_name: kafka-init
    depends_on:
      - kafka
    env_file:
      - local-docker.env
    entrypoint: [ '/bin/bash', '-c' ]
    networks:
      - internal
    command: |
      "      
      # blocks until kafka is reachable
      echo -e 'Currently available topics:'
      kafka-topics --bootstrap-server kafka:9092 --list
      
      echo -e 'Creating kafka topics...'
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_TASKS} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_DATA_ENTRIES} --replication-factor 1 --partitions 1

      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_COCREATION_DEPLOY} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_COCREATION} --replication-factor 1 --partitions 1

      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_ENGINE} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPIC_ENGINE_DLQ} --replication-factor 1 --partitions 1
      
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_CONNECTOR} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_CONNECTOR_DLQ} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_CONNECTOR_INCIDENT} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_CONNECTOR_BPMNERROR} --replication-factor 1 --partitions 1
      
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_EMAIL_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_S3_CLIENT_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_S3_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_S3_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_COSYS_INTEGRATION} --replication-factor 1 --partitions 1
      kafka-topics --bootstrap-server kafka:9092 --create --if-not-exists --topic $${KAFKA_TOPICS_ALW_INTEGRATION} --replication-factor 1 --partitions 1  

      echo -e 'Resulting topics:'
      kafka-topics --bootstrap-server kafka:9092 --list
      "

  minio:
    image: quay.io/minio/minio:latest
    container_name: minio
    command: server /data --console-address ":9001"
    environment:
      MINIO_ROOT_USER: minio
      MINIO_ROOT_PASSWORD: Test1234
    ports:
      - '9000:9000'
      - '9001:9001'
    volumes:
      - ./minio:/data
    networks:
      - internal

  mailhog:
    image: mailhog/mailhog:latest
    container_name: mailhog
    ports:
      - '1025:1025' # smtp server
      - '9025:8025' # ui
    networks:
      - internal

  #
  # Local keycloak. To work properly, you need to change your local hosts file and add an alias to your
  # `127.0.0.1 localhost` line to look like this: `127.0.0.1 localhost keycloak`.
  # On Mac/Linux it is located in `/etc/hosts` on Win `C:\Windows\System32\Drivers\etc\hosts`
  #
  keycloak:
    image: ${KEYCLOAK_IMAGE:-quay.io/keycloak/keycloak:20.0.3}
    container_name: keycloak
    depends_on:
      - postgres-keycloak
    ports:
      - '8080:8080'
    command: 'start-dev --http-relative-path /auth'
    environment:
      KC_HOSTNAME: keycloak # this hostname must be resolved to 127.0.0.1 locally. Add it to your hosts file.
      KC_HOSTNAME_STRICT: 'false'
      KC_DB: postgres
      KC_DB_URL: jdbc:postgresql://postgres-keycloak:5432/keycloak
      KC_DB_USERNAME: keycloak-user
      KC_DB_PASSWORD: keycloak-secret
      KEYCLOAK_ADMIN: admin
      KEYCLOAK_ADMIN_PASSWORD: admin
    networks:
      - local-keycloak
      - internal

  keycloak-init:
    image: klg71/keycloakmigration
    container_name: keycloak-init
    depends_on:
      - keycloak
    env_file:
      - './local-docker.env'
    environment:
      ADMIN_USER: admin
      ADMIN_PASSWORD: admin
      BASEURL: http://keycloak:8080/auth # uses internal docker network to access the keycloak via its back channel port
      WAIT_FOR_KEYCLOAK: 'true'
      KEYCLOAK_CHANGELOG: /migration/keycloak-changelog.yml
    volumes:
      - './keycloak:/migration'
    networks:
      - local-keycloak

  postgres-engine:
    image: postgres:13.2
    container_name: postgres-engine
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: enginedb
    ports:
      - '25433:5432'
    networks:
      - internal

  postgres-tasklist:
    image: postgres:13.2
    container_name: postgres-tasklist
    environment:
      POSTGRES_USER: user
      POSTGRES_PASSWORD: secret
      POSTGRES_DB: tasklistdb
    ports:
      - '25432:5432'
    networks:
      - internal

  postgres-keycloak:
    image: postgres:13.2
    container_name: postgres-keycloak
    environment:
      POSTGRES_DB: keycloak
      POSTGRES_USER: keycloak-user
      POSTGRES_PASSWORD: keycloak-secret
    networks:
      - local-keycloak

networks:
  local-keycloak:
  internal:
